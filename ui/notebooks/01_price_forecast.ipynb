{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FinSim Price Forecasting with LSTM, Transformer & GRU\n",
    "\n",
    "This notebook demonstrates advanced price prediction techniques using deep learning models in the FinSim platform.\n",
    "\n",
    "## Overview\n",
    "- LSTM (Long Short-Term Memory) networks for sequential pattern recognition\n",
    "- Transformer models with attention mechanisms for complex temporal relationships\n",
    "- GRU (Gated Recurrent Unit) networks for efficient sequence processing\n",
    "\n",
    "## References\n",
    "- Hochreiter, S., & Schmidhuber, J. \"Long Short-Term Memory.\" Neural Computation, 1997.\n",
    "- Vaswani, A. et al. \"Attention Is All You Need.\" NeurIPS, 2017."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import requests\n",
    "import yfinance as yf\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# FinSim API configuration\n",
    "FINSIM_API_BASE = \"http://localhost:8000/api/v1\"\n",
    "SYMBOLS = ['AAPL', 'GOOGL', 'MSFT', 'TSLA', 'NVDA']\n",
    "\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Collection and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_market_data(symbol, period='2y'):\n",
    "    \"\"\"Fetch historical market data\"\"\"\n",
    "    try:\n",
    "        # Try FinSim API first\n",
    "        response = requests.post(f\"{FINSIM_API_BASE}/historical\", \n",
    "                               json={\"symbols\": [symbol], \"interval\": \"1d\"})\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()[symbol]['data']\n",
    "            return pd.DataFrame(data)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # Fallback to Yahoo Finance\n",
    "    ticker = yf.Ticker(symbol)\n",
    "    data = ticker.history(period=period)\n",
    "    return data.reset_index()\n",
    "\n",
    "def prepare_features(df):\n",
    "    \"\"\"Create technical indicators and features\"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Price features\n",
    "    df['returns'] = df['Close'].pct_change()\n",
    "    df['log_returns'] = np.log(df['Close'] / df['Close'].shift(1))\n",
    "    \n",
    "    # Technical indicators\n",
    "    df['sma_5'] = df['Close'].rolling(5).mean()\n",
    "    df['sma_20'] = df['Close'].rolling(20).mean()\n",
    "    df['sma_50'] = df['Close'].rolling(50).mean()\n",
    "    \n",
    "    # Volatility\n",
    "    df['volatility'] = df['returns'].rolling(20).std()\n",
    "    \n",
    "    # Volume indicators\n",
    "    df['volume_sma'] = df['Volume'].rolling(20).mean()\n",
    "    df['volume_ratio'] = df['Volume'] / df['volume_sma']\n",
    "    \n",
    "    # RSI\n",
    "    delta = df['Close'].diff()\n",
    "    gain = (delta.where(delta > 0, 0)).rolling(14).mean()\n",
    "    loss = (-delta.where(delta < 0, 0)).rolling(14).mean()\n",
    "    rs = gain / loss\n",
    "    df['rsi'] = 100 - (100 / (1 + rs))\n",
    "    \n",
    "    # Bollinger Bands\n",
    "    df['bb_upper'] = df['sma_20'] + (df['Close'].rolling(20).std() * 2)\n",
    "    df['bb_lower'] = df['sma_20'] - (df['Close'].rolling(20).std() * 2)\n",
    "    df['bb_position'] = (df['Close'] - df['bb_lower']) / (df['bb_upper'] - df['bb_lower'])\n",
    "    \n",
    "    return df.dropna()\n",
    "\n",
    "# Collect data for all symbols\n",
    "data_dict = {}\n",
    "for symbol in SYMBOLS:\n",
    "    print(f\"Fetching data for {symbol}...\")\n",
    "    df = fetch_market_data(symbol)\n",
    "    df = prepare_features(df)\n",
    "    data_dict[symbol] = df\n",
    "    print(f\"  {len(df)} records collected\")\n",
    "\n",
    "print(\"\\nData collection completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. LSTM Model Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size=50, num_layers=2, dropout=0.2, output_size=1):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, \n",
    "                           dropout=dropout, batch_first=True)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        \n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = self.dropout(out[:, -1, :])  # Take last time step\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "def create_sequences(data, seq_length=20):\n",
    "    \"\"\"Create sequences for training\"\"\"\n",
    "    sequences = []\n",
    "    targets = []\n",
    "    \n",
    "    for i in range(len(data) - seq_length):\n",
    "        seq = data[i:i+seq_length]\n",
    "        target = data[i+seq_length]\n",
    "        sequences.append(seq)\n",
    "        targets.append(target)\n",
    "    \n",
    "    return np.array(sequences), np.array(targets)\n",
    "\n",
    "def train_lstm_model(symbol, data_dict, seq_length=20, epochs=100):\n",
    "    \"\"\"Train LSTM model for a specific symbol\"\"\"\n",
    "    df = data_dict[symbol]\n",
    "    \n",
    "    # Select features\n",
    "    feature_cols = ['Close', 'Volume', 'returns', 'sma_5', 'sma_20', 'volatility', 'rsi', 'bb_position']\n",
    "    features = df[feature_cols].values\n",
    "    \n",
    "    # Normalize features\n",
    "    scaler = MinMaxScaler()\n",
    "    features_scaled = scaler.fit_transform(features)\n",
    "    \n",
    "    # Create sequences\n",
    "    X, y = create_sequences(features_scaled, seq_length)\n",
    "    \n",
    "    # Split train/test\n",
    "    split_idx = int(0.8 * len(X))\n",
    "    X_train, X_test = X[:split_idx], X[split_idx:]\n",
    "    y_train, y_test = y[:split_idx], y[split_idx:]\n",
    "    \n",
    "    # Convert to tensors\n",
    "    X_train = torch.FloatTensor(X_train)\n",
    "    y_train = torch.FloatTensor(y_train[:, 0])  # Predict Close price\n",
    "    X_test = torch.FloatTensor(X_test)\n",
    "    y_test = torch.FloatTensor(y_test[:, 0])\n",
    "    \n",
    "    # Initialize model\n",
    "    model = LSTMModel(input_size=len(feature_cols))\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    # Training loop\n",
    "    train_losses = []\n",
    "    model.train()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_train)\n",
    "        loss = criterion(outputs.squeeze(), y_train)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_losses.append(loss.item())\n",
    "        \n",
    "        if (epoch + 1) % 20 == 0:\n",
    "            print(f\"Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.6f}\")\n",
    "    \n",
    "    # Evaluation\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_pred = model(X_train).squeeze()\n",
    "        test_pred = model(X_test).squeeze()\n",
    "    \n",
    "    # Calculate metrics\n",
    "    train_mse = mean_squared_error(y_train.numpy(), train_pred.numpy())\n",
    "    test_mse = mean_squared_error(y_test.numpy(), test_pred.numpy())\n",
    "    train_mae = mean_absolute_error(y_train.numpy(), train_pred.numpy())\n",
    "    test_mae = mean_absolute_error(y_test.numpy(), test_pred.numpy())\n",
    "    \n",
    "    print(f\"\\nLSTM Results for {symbol}:\")\n",
    "    print(f\"Train MSE: {train_mse:.6f}, Test MSE: {test_mse:.6f}\")\n",
    "    print(f\"Train MAE: {train_mae:.6f}, Test MAE: {test_mae:.6f}\")\n",
    "    \n",
    "    return {\n",
    "        'model': model,\n",
    "        'scaler': scaler,\n",
    "        'train_losses': train_losses,\n",
    "        'predictions': {\n",
    "            'train': train_pred.numpy(),\n",
    "            'test': test_pred.numpy(),\n",
    "            'y_train': y_train.numpy(),\n",
    "            'y_test': y_test.numpy()\n",
    "        },\n",
    "        'metrics': {\n",
    "            'train_mse': train_mse,\n",
    "            'test_mse': test_mse,\n",
    "            'train_mae': train_mae,\n",
    "            'test_mae': test_mae\n",
    "        }\n",
    "    }\n",
    "\n",
    "# Train LSTM for AAPL\n",
    "print(\"Training LSTM model for AAPL...\")\n",
    "lstm_results = train_lstm_model('AAPL', data_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Transformer Model Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        assert d_model % num_heads == 0\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads\n",
    "        self.d_k = d_model // num_heads\n",
    "        \n",
    "        self.W_q = nn.Linear(d_model, d_model)\n",
    "        self.W_k = nn.Linear(d_model, d_model)\n",
    "        self.W_v = nn.Linear(d_model, d_model)\n",
    "        self.W_o = nn.Linear(d_model, d_model)\n",
    "        \n",
    "    def scaled_dot_product_attention(self, Q, K, V):\n",
    "        attn_scores = torch.matmul(Q, K.transpose(-2, -1)) / np.sqrt(self.d_k)\n",
    "        attn_probs = torch.softmax(attn_scores, dim=-1)\n",
    "        output = torch.matmul(attn_probs, V)\n",
    "        return output\n",
    "        \n",
    "    def forward(self, x):\n",
    "        batch_size, seq_length, d_model = x.size()\n",
    "        \n",
    "        Q = self.W_q(x).view(batch_size, seq_length, self.num_heads, self.d_k).transpose(1, 2)\n",
    "        K = self.W_k(x).view(batch_size, seq_length, self.num_heads, self.d_k).transpose(1, 2)\n",
    "        V = self.W_v(x).view(batch_size, seq_length, self.num_heads, self.d_k).transpose(1, 2)\n",
    "        \n",
    "        attn_output = self.scaled_dot_product_attention(Q, K, V)\n",
    "        attn_output = attn_output.transpose(1, 2).contiguous().view(\n",
    "            batch_size, seq_length, d_model)\n",
    "        \n",
    "        output = self.W_o(attn_output)\n",
    "        return output\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.attention = MultiHeadAttention(d_model, num_heads)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        \n",
    "        self.feed_forward = nn.Sequential(\n",
    "            nn.Linear(d_model, d_ff),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(d_ff, d_model)\n",
    "        )\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        attn_output = self.attention(x)\n",
    "        x = self.norm1(x + self.dropout(attn_output))\n",
    "        \n",
    "        ff_output = self.feed_forward(x)\n",
    "        x = self.norm2(x + self.dropout(ff_output))\n",
    "        \n",
    "        return x\n",
    "\n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, input_size, d_model=128, num_heads=8, num_layers=3, d_ff=512, dropout=0.1):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.input_projection = nn.Linear(input_size, d_model)\n",
    "        self.positional_encoding = self.create_positional_encoding(1000, d_model)\n",
    "        \n",
    "        self.transformer_blocks = nn.ModuleList([\n",
    "            TransformerBlock(d_model, num_heads, d_ff, dropout)\n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "        \n",
    "        self.ln_f = nn.LayerNorm(d_model)\n",
    "        self.fc = nn.Linear(d_model, 1)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def create_positional_encoding(self, max_seq_length, d_model):\n",
    "        pe = torch.zeros(max_seq_length, d_model)\n",
    "        position = torch.arange(0, max_seq_length, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * \n",
    "                           (-np.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        return pe.unsqueeze(0)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        seq_length = x.size(1)\n",
    "        x = self.input_projection(x) * np.sqrt(self.d_model)\n",
    "        x = x + self.positional_encoding[:, :seq_length, :].to(x.device)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        for transformer in self.transformer_blocks:\n",
    "            x = transformer(x)\n",
    "            \n",
    "        x = self.ln_f(x)\n",
    "        x = self.fc(x[:, -1, :])  # Take last time step\n",
    "        return x\n",
    "\n",
    "def train_transformer_model(symbol, data_dict, seq_length=20, epochs=100):\n",
    "    \"\"\"Train Transformer model for a specific symbol\"\"\"\n",
    "    df = data_dict[symbol]\n",
    "    \n",
    "    # Select features\n",
    "    feature_cols = ['Close', 'Volume', 'returns', 'sma_5', 'sma_20', 'volatility', 'rsi', 'bb_position']\n",
    "    features = df[feature_cols].values\n",
    "    \n",
    "    # Normalize features\n",
    "    scaler = MinMaxScaler()\n",
    "    features_scaled = scaler.fit_transform(features)\n",
    "    \n",
    "    # Create sequences\n",
    "    X, y = create_sequences(features_scaled, seq_length)\n",
    "    \n",
    "    # Split train/test\n",
    "    split_idx = int(0.8 * len(X))\n",
    "    X_train, X_test = X[:split_idx], X[split_idx:]\n",
    "    y_train, y_test = y[:split_idx], y[split_idx:]\n",
    "    \n",
    "    # Convert to tensors\n",
    "    X_train = torch.FloatTensor(X_train)\n",
    "    y_train = torch.FloatTensor(y_train[:, 0])  # Predict Close price\n",
    "    X_test = torch.FloatTensor(X_test)\n",
    "    y_test = torch.FloatTensor(y_test[:, 0])\n",
    "    \n",
    "    # Initialize model\n",
    "    model = TransformerModel(input_size=len(feature_cols))\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    # Training loop\n",
    "    train_losses = []\n",
    "    model.train()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_train)\n",
    "        loss = criterion(outputs.squeeze(), y_train)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_losses.append(loss.item())\n",
    "        \n",
    "        if (epoch + 1) % 20 == 0:\n",
    "            print(f\"Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.6f}\")\n",
    "    \n",
    "    # Evaluation\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_pred = model(X_train).squeeze()\n",
    "        test_pred = model(X_test).squeeze()\n",
    "    \n",
    "    # Calculate metrics\n",
    "    train_mse = mean_squared_error(y_train.numpy(), train_pred.numpy())\n",
    "    test_mse = mean_squared_error(y_test.numpy(), test_pred.numpy())\n",
    "    train_mae = mean_absolute_error(y_train.numpy(), train_pred.numpy())\n",
    "    test_mae = mean_absolute_error(y_test.numpy(), test_pred.numpy())\n",
    "    \n",
    "    print(f\"\\nTransformer Results for {symbol}:\")\n",
    "    print(f\"Train MSE: {train_mse:.6f}, Test MSE: {test_mse:.6f}\")\n",
    "    print(f\"Train MAE: {train_mae:.6f}, Test MAE: {test_mae:.6f}\")\n",
    "    \n",
    "    return {\n",
    "        'model': model,\n",
    "        'scaler': scaler,\n",
    "        'train_losses': train_losses,\n",
    "        'predictions': {\n",
    "            'train': train_pred.numpy(),\n",
    "            'test': test_pred.numpy(),\n",
    "            'y_train': y_train.numpy(),\n",
    "            'y_test': y_test.numpy()\n",
    "        },\n",
    "        'metrics': {\n",
    "            'train_mse': train_mse,\n",
    "            'test_mse': test_mse,\n",
    "            'train_mae': train_mae,\n",
    "            'test_mae': test_mae\n",
    "        }\n",
    "    }\n",
    "\n",
    "# Train Transformer for AAPL\n",
    "print(\"Training Transformer model for AAPL...\")\n",
    "transformer_results = train_transformer_model('AAPL', data_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. GRU Model Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size=50, num_layers=2, dropout=0.2, output_size=1):\n",
    "        super(GRUModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.gru = nn.GRU(input_size, hidden_size, num_layers, \n",
    "                         dropout=dropout, batch_first=True)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        \n",
    "        out, _ = self.gru(x, h0)\n",
    "        out = self.dropout(out[:, -1, :])  # Take last time step\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "def train_gru_model(symbol, data_dict, seq_length=20, epochs=100):\n",
    "    \"\"\"Train GRU model for a specific symbol\"\"\"\n",
    "    df = data_dict[symbol]\n",
    "    \n",
    "    # Select features\n",
    "    feature_cols = ['Close', 'Volume', 'returns', 'sma_5', 'sma_20', 'volatility', 'rsi', 'bb_position']\n",
    "    features = df[feature_cols].values\n",
    "    \n",
    "    # Normalize features\n",
    "    scaler = MinMaxScaler()\n",
    "    features_scaled = scaler.fit_transform(features)\n",
    "    \n",
    "    # Create sequences\n",
    "    X, y = create_sequences(features_scaled, seq_length)\n",
    "    \n",
    "    # Split train/test\n",
    "    split_idx = int(0.8 * len(X))\n",
    "    X_train, X_test = X[:split_idx], X[split_idx:]\n",
    "    y_train, y_test = y[:split_idx], y[split_idx:]\n",
    "    \n",
    "    # Convert to tensors\n",
    "    X_train = torch.FloatTensor(X_train)\n",
    "    y_train = torch.FloatTensor(y_train[:, 0])  # Predict Close price\n",
    "    X_test = torch.FloatTensor(X_test)\n",
    "    y_test = torch.FloatTensor(y_test[:, 0])\n",
    "    \n",
    "    # Initialize model\n",
    "    model = GRUModel(input_size=len(feature_cols))\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    # Training loop\n",
    "    train_losses = []\n",
    "    model.train()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_train)\n",
    "        loss = criterion(outputs.squeeze(), y_train)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_losses.append(loss.item())\n",
    "        \n",
    "        if (epoch + 1) % 20 == 0:\n",
    "            print(f\"Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.6f}\")\n",
    "    \n",
    "    # Evaluation\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_pred = model(X_train).squeeze()\n",
    "        test_pred = model(X_test).squeeze()\n",
    "    \n",
    "    # Calculate metrics\n",
    "    train_mse = mean_squared_error(y_train.numpy(), train_pred.numpy())\n",
    "    test_mse = mean_squared_error(y_test.numpy(), test_pred.numpy())\n",
    "    train_mae = mean_absolute_error(y_train.numpy(), train_pred.numpy())\n",
    "    test_mae = mean_absolute_error(y_test.numpy(), test_pred.numpy())\n",
    "    \n",
    "    print(f\"\\nGRU Results for {symbol}:\")\n",
    "    print(f\"Train MSE: {train_mse:.6f}, Test MSE: {test_mse:.6f}\")\n",
    "    print(f\"Train MAE: {train_mae:.6f}, Test MAE: {test_mae:.6f}\")\n",
    "    \n",
    "    return {\n",
    "        'model': model,\n",
    "        'scaler': scaler,\n",
    "        'train_losses': train_losses,\n",
    "        'predictions': {\n",
    "            'train': train_pred.numpy(),\n",
    "            'test': test_pred.numpy(),\n",
    "            'y_train': y_train.numpy(),\n",
    "            'y_test': y_test.numpy()\n",
    "        },\n",
    "        'metrics': {\n",
    "            'train_mse': train_mse,\n",
    "            'test_mse': test_mse,\n",
    "            'train_mae': train_mae,\n",
    "            'test_mae': test_mae\n",
    "        }\n",
    "    }\n",
    "\n",
    "# Train GRU for AAPL\n",
    "print(\"Training GRU model for AAPL...\")\n",
    "gru_results = train_gru_model('AAPL', data_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Comparison and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare model performance\n",
    "models = {\n",
    "    'LSTM': lstm_results,\n",
    "    'Transformer': transformer_results,\n",
    "    'GRU': gru_results\n",
    "}\n",
    "\n",
    "# Create comparison dataframe\n",
    "comparison_data = []\n",
    "for model_name, results in models.items():\n",
    "    comparison_data.append({\n",
    "        'Model': model_name,\n",
    "        'Train MSE': results['metrics']['train_mse'],\n",
    "        'Test MSE': results['metrics']['test_mse'],\n",
    "        'Train MAE': results['metrics']['train_mae'],\n",
    "        'Test MAE': results['metrics']['test_mae']\n",
    "    })\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "print(\"\\nModel Comparison:\")\n",
    "print(comparison_df.round(6))\n",
    "\n",
    "# Visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "fig.suptitle('Price Prediction Models Comparison - AAPL', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Training losses\n",
    "axes[0, 0].set_title('Training Losses')\n",
    "for model_name, results in models.items():\n",
    "    axes[0, 0].plot(results['train_losses'], label=model_name, alpha=0.8)\n",
    "axes[0, 0].set_xlabel('Epoch')\n",
    "axes[0, 0].set_ylabel('MSE Loss')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].set_yscale('log')\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Test predictions comparison\n",
    "axes[0, 1].set_title('Test Set Predictions')\n",
    "test_indices = range(len(lstm_results['predictions']['y_test']))\n",
    "axes[0, 1].plot(test_indices, lstm_results['predictions']['y_test'], \n",
    "                label='Actual', color='black', linewidth=2)\n",
    "for model_name, results in models.items():\n",
    "    axes[0, 1].plot(test_indices, results['predictions']['test'], \n",
    "                    label=f'{model_name} Pred', alpha=0.8)\n",
    "axes[0, 1].set_xlabel('Time Steps')\n",
    "axes[0, 1].set_ylabel('Normalized Price')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Model performance metrics\n",
    "metrics = ['Train MSE', 'Test MSE', 'Train MAE', 'Test MAE']\n",
    "x = np.arange(len(metrics))\n",
    "width = 0.25\n",
    "\n",
    "for i, (model_name, results) in enumerate(models.items()):\n",
    "    values = [results['metrics']['train_mse'], results['metrics']['test_mse'],\n",
    "             results['metrics']['train_mae'], results['metrics']['test_mae']]\n",
    "    axes[1, 0].bar(x + i*width, values, width, label=model_name, alpha=0.8)\n",
    "\n",
    "axes[1, 0].set_title('Performance Metrics Comparison')\n",
    "axes[1, 0].set_xlabel('Metrics')\n",
    "axes[1, 0].set_ylabel('Error Value')\n",
    "axes[1, 0].set_xticks(x + width)\n",
    "axes[1, 0].set_xticklabels(metrics, rotation=45)\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Prediction accuracy scatter plot\n",
    "axes[1, 1].set_title('Prediction vs Actual (Test Set)')\n",
    "for model_name, results in models.items():\n",
    "    axes[1, 1].scatter(results['predictions']['y_test'], \n",
    "                      results['predictions']['test'], \n",
    "                      alpha=0.6, label=model_name, s=20)\n",
    "\n",
    "# Perfect prediction line\n",
    "min_val = min([min(results['predictions']['y_test']) for results in models.values()])\n",
    "max_val = max([max(results['predictions']['y_test']) for results in models.values()])\n",
    "axes[1, 1].plot([min_val, max_val], [min_val, max_val], \n",
    "                'r--', alpha=0.8, label='Perfect Prediction')\n",
    "\n",
    "axes[1, 1].set_xlabel('Actual Values')\n",
    "axes[1, 1].set_ylabel('Predicted Values')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print best model\n",
    "best_model = comparison_df.loc[comparison_df['Test MSE'].idxmin(), 'Model']\n",
    "print(f\"\\n🏆 Best performing model: {best_model}\")\n",
    "print(f\"Test MSE: {comparison_df.loc[comparison_df['Test MSE'].idxmin(), 'Test MSE']:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Live Prediction with FinSim Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deploy_model_to_finsim(model_results, symbol, model_type):\n",
    "    \"\"\"Deploy trained model as a FinSim agent\"\"\"\n",
    "    \n",
    "    agent_config = {\n",
    "        \"agent_id\": f\"{model_type}_predictor_{symbol}\",\n",
    "        \"agent_type\": model_type.lower(),\n",
    "        \"symbols\": [symbol],\n",
    "        \"parameters\": {\n",
    "            \"model_path\": f\"models/{model_type}_{symbol}.pth\",\n",
    "            \"sequence_length\": 20,\n",
    "            \"confidence_threshold\": 0.6\n",
    "        },\n",
    "        \"enabled\": True\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.post(f\"{FINSIM_API_BASE}/agents\", json=agent_config)\n",
    "        if response.status_code == 200:\n",
    "            print(f\"✅ {model_type} agent deployed successfully for {symbol}\")\n",
    "            return response.json()\n",
    "        else:\n",
    "            print(f\"❌ Failed to deploy {model_type} agent: {response.text}\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error deploying agent: {e}\")\n",
    "    \n",
    "    return None\n",
    "\n",
    "def make_live_prediction(model_results, symbol, model_type):\n",
    "    \"\"\"Make live predictions using trained model\"\"\"\n",
    "    model = model_results['model']\n",
    "    scaler = model_results['scaler']\n",
    "    \n",
    "    # Get latest market data\n",
    "    try:\n",
    "        response = requests.get(f\"{FINSIM_API_BASE}/quotes/{symbol}\")\n",
    "        if response.status_code == 200:\n",
    "            quote = response.json()\n",
    "            \n",
    "            # Prepare features (simplified for demo)\n",
    "            current_features = np.array([\n",
    "                quote['price'],\n",
    "                quote['volume'],\n",
    "                0.0,  # returns (would need historical data)\n",
    "                quote['price'],  # sma_5 (simplified)\n",
    "                quote['price'],  # sma_20 (simplified)\n",
    "                0.02,  # volatility (estimated)\n",
    "                50.0,  # rsi (neutral)\n",
    "                0.5   # bb_position (middle)\n",
    "            ]).reshape(1, -1)\n",
    "            \n",
    "            # Normalize features\n",
    "            current_features_scaled = scaler.transform(current_features)\n",
    "            \n",
    "            # Create sequence (repeat current features for sequence length)\n",
    "            sequence = np.repeat(current_features_scaled, 20, axis=0).reshape(1, 20, -1)\n",
    "            \n",
    "            # Make prediction\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                prediction = model(torch.FloatTensor(sequence))\n",
    "                predicted_price = prediction.item()\n",
    "            \n",
    "            # Calculate prediction confidence and direction\n",
    "            current_price_normalized = current_features_scaled[0, 0]\n",
    "            price_change = predicted_price - current_price_normalized\n",
    "            direction = \"UP\" if price_change > 0 else \"DOWN\"\n",
    "            confidence = min(abs(price_change) * 100, 100)  # Simplified confidence\n",
    "            \n",
    "            return {\n",
    "                'symbol': symbol,\n",
    "                'model': model_type,\n",
    "                'current_price': quote['price'],\n",
    "                'predicted_direction': direction,\n",
    "                'confidence': confidence,\n",
    "                'prediction_raw': predicted_price,\n",
    "                'timestamp': datetime.now().isoformat()\n",
    "            }\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error making live prediction: {e}\")\n",
    "    \n",
    "    return None\n",
    "\n",
    "# Deploy best model to FinSim\n",
    "print(\"\\nDeploying models to FinSim...\")\n",
    "for model_name, results in models.items():\n",
    "    deploy_model_to_finsim(results, 'AAPL', model_name)\n",
    "\n",
    "# Make live predictions\n",
    "print(\"\\nMaking live predictions...\")\n",
    "live_predictions = []\n",
    "for model_name, results in models.items():\n",
    "    prediction = make_live_prediction(results, 'AAPL', model_name)\n",
    "    if prediction:\n",
    "        live_predictions.append(prediction)\n",
    "\n",
    "# Display predictions\n",
    "if live_predictions:\n",
    "    predictions_df = pd.DataFrame(live_predictions)\n",
    "    print(\"\\nLive Price Predictions:\")\n",
    "    print(predictions_df[['model', 'current_price', 'predicted_direction', 'confidence']].round(2))\n",
    "else:\n",
    "    print(\"No live predictions available (API not accessible)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"PREDICTION NOTEBOOK COMPLETED SUCCESSFULLY!\")\n",
    "print(\"Models trained:\", list(models.keys()))\n",
    "print(f\"Best model: {best_model}\")\n",
    "print(\"=\"*50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}